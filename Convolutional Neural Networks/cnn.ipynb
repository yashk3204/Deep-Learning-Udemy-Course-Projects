{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 35
    },
    "id": "6jepZgXeu9je",
    "outputId": "ef2fdd9f-fa33-4088-be23-23e9d078a5a3"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'2.18.0'"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import tensorflow as tf\n",
    "from tensorflow.keras.preprocessing.image import ImageDataGenerator\n",
    "tf.__version__"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "mMm-VoLO7fAb"
   },
   "source": [
    "Preprocessing the training and test set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "id": "jLhbe-bu4jh4"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 8000 images belonging to 2 classes.\n"
     ]
    }
   ],
   "source": [
    "train_gen = ImageDataGenerator(rescale=1./255,\n",
    "                               shear_range=0.2,\n",
    "                               zoom_range=0.2,\n",
    "                               horizontal_flip=True)\n",
    "\n",
    "train_set = train_gen.flow_from_directory(\n",
    "    'dataset/training_set',\n",
    "    target_size=(64, 64),\n",
    "    batch_size=32,\n",
    "    class_mode='binary'\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "id": "FL8ETzOJ6-UJ"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 2000 images belonging to 2 classes.\n"
     ]
    }
   ],
   "source": [
    "test_gen = ImageDataGenerator(rescale=1./255)\n",
    "\n",
    "test_set = test_gen.flow_from_directory(\n",
    "    'dataset/test_set',\n",
    "    target_size=(64, 64),\n",
    "    batch_size=32,\n",
    "    class_mode='binary'\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "MGMABvu_7lg_"
   },
   "source": [
    "Building and Training the CNN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "id": "D9COGqs27nVx"
   },
   "outputs": [],
   "source": [
    "cnn = tf.keras.models.Sequential()\n",
    "cnn.add(tf.keras.layers.Input(shape=[64, 64, 3])) # Input layer\n",
    "cnn.add(tf.keras.layers.Conv2D(filters=32, kernel_size=3, activation='relu')) # 1st convolution layer\n",
    "cnn.add(tf.keras.layers.MaxPool2D(pool_size=2, strides=2)) # Max pooling layer\n",
    "cnn.add(tf.keras.layers.Conv2D(filters=32, kernel_size=3, activation='relu')) # 2nd convolution layer\n",
    "cnn.add(tf.keras.layers.MaxPool2D(pool_size=2, strides=2)) # 2nd max pooling layer\n",
    "cnn.add(tf.keras.layers.Flatten()) # Flattening layer\n",
    "cnn.add(tf.keras.layers.Dense(units=128, activation='relu')) # Full connection layer\n",
    "cnn.add(tf.keras.layers.Dense(units=1, activation='sigmoid')) # Output layer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "id": "6JLgwT90GbBi"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\yashk\\Anaconda\\Lib\\site-packages\\keras\\src\\trainers\\data_adapters\\py_dataset_adapter.py:121: UserWarning: Your `PyDataset` class should call `super().__init__(**kwargs)` in its constructor. `**kwargs` can include `workers`, `use_multiprocessing`, `max_queue_size`. Do not pass these arguments to `fit()`, as they will be ignored.\n",
      "  self._warn_if_super_not_called()\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/25\n",
      "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 587ms/step - accuracy: 0.5460 - loss: 0.6927"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\yashk\\Anaconda\\Lib\\site-packages\\keras\\src\\trainers\\data_adapters\\py_dataset_adapter.py:121: UserWarning: Your `PyDataset` class should call `super().__init__(**kwargs)` in its constructor. `**kwargs` can include `workers`, `use_multiprocessing`, `max_queue_size`. Do not pass these arguments to `fit()`, as they will be ignored.\n",
      "  self._warn_if_super_not_called()\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m178s\u001b[0m 705ms/step - accuracy: 0.5462 - loss: 0.6926 - val_accuracy: 0.6605 - val_loss: 0.6162\n",
      "Epoch 2/25\n",
      "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m34s\u001b[0m 137ms/step - accuracy: 0.6627 - loss: 0.6113 - val_accuracy: 0.6825 - val_loss: 0.6005\n",
      "Epoch 3/25\n",
      "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m44s\u001b[0m 177ms/step - accuracy: 0.7013 - loss: 0.5782 - val_accuracy: 0.7245 - val_loss: 0.5516\n",
      "Epoch 4/25\n",
      "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m43s\u001b[0m 171ms/step - accuracy: 0.7155 - loss: 0.5504 - val_accuracy: 0.7265 - val_loss: 0.5558\n",
      "Epoch 5/25\n",
      "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m39s\u001b[0m 156ms/step - accuracy: 0.7418 - loss: 0.5195 - val_accuracy: 0.7475 - val_loss: 0.5113\n",
      "Epoch 6/25\n",
      "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m37s\u001b[0m 149ms/step - accuracy: 0.7506 - loss: 0.5013 - val_accuracy: 0.7610 - val_loss: 0.4989\n",
      "Epoch 7/25\n",
      "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m42s\u001b[0m 170ms/step - accuracy: 0.7679 - loss: 0.4847 - val_accuracy: 0.7675 - val_loss: 0.4824\n",
      "Epoch 8/25\n",
      "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m49s\u001b[0m 197ms/step - accuracy: 0.7772 - loss: 0.4657 - val_accuracy: 0.7750 - val_loss: 0.4864\n",
      "Epoch 9/25\n",
      "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m52s\u001b[0m 207ms/step - accuracy: 0.7823 - loss: 0.4495 - val_accuracy: 0.7675 - val_loss: 0.4876\n",
      "Epoch 10/25\n",
      "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m43s\u001b[0m 172ms/step - accuracy: 0.7915 - loss: 0.4472 - val_accuracy: 0.7745 - val_loss: 0.4779\n",
      "Epoch 11/25\n",
      "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m41s\u001b[0m 165ms/step - accuracy: 0.7901 - loss: 0.4382 - val_accuracy: 0.7865 - val_loss: 0.4746\n",
      "Epoch 12/25\n",
      "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m42s\u001b[0m 166ms/step - accuracy: 0.8094 - loss: 0.4127 - val_accuracy: 0.7545 - val_loss: 0.5182\n",
      "Epoch 13/25\n",
      "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m37s\u001b[0m 149ms/step - accuracy: 0.8097 - loss: 0.4149 - val_accuracy: 0.7865 - val_loss: 0.4684\n",
      "Epoch 14/25\n",
      "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m38s\u001b[0m 150ms/step - accuracy: 0.8269 - loss: 0.3914 - val_accuracy: 0.7595 - val_loss: 0.5259\n",
      "Epoch 15/25\n",
      "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m38s\u001b[0m 150ms/step - accuracy: 0.8208 - loss: 0.3959 - val_accuracy: 0.7910 - val_loss: 0.4646\n",
      "Epoch 16/25\n",
      "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m38s\u001b[0m 151ms/step - accuracy: 0.8119 - loss: 0.4025 - val_accuracy: 0.7880 - val_loss: 0.4725\n",
      "Epoch 17/25\n",
      "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m36s\u001b[0m 146ms/step - accuracy: 0.8357 - loss: 0.3731 - val_accuracy: 0.7945 - val_loss: 0.4717\n",
      "Epoch 18/25\n",
      "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m39s\u001b[0m 157ms/step - accuracy: 0.8396 - loss: 0.3587 - val_accuracy: 0.7900 - val_loss: 0.4786\n",
      "Epoch 19/25\n",
      "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m36s\u001b[0m 145ms/step - accuracy: 0.8333 - loss: 0.3642 - val_accuracy: 0.7870 - val_loss: 0.4778\n",
      "Epoch 20/25\n",
      "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m36s\u001b[0m 143ms/step - accuracy: 0.8368 - loss: 0.3553 - val_accuracy: 0.7990 - val_loss: 0.4629\n",
      "Epoch 21/25\n",
      "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m36s\u001b[0m 144ms/step - accuracy: 0.8482 - loss: 0.3455 - val_accuracy: 0.8070 - val_loss: 0.4520\n",
      "Epoch 22/25\n",
      "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m37s\u001b[0m 148ms/step - accuracy: 0.8563 - loss: 0.3336 - val_accuracy: 0.8110 - val_loss: 0.4475\n",
      "Epoch 23/25\n",
      "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m37s\u001b[0m 148ms/step - accuracy: 0.8549 - loss: 0.3261 - val_accuracy: 0.8200 - val_loss: 0.4422\n",
      "Epoch 24/25\n",
      "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m37s\u001b[0m 148ms/step - accuracy: 0.8606 - loss: 0.3211 - val_accuracy: 0.8105 - val_loss: 0.4462\n",
      "Epoch 25/25\n",
      "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m36s\u001b[0m 145ms/step - accuracy: 0.8669 - loss: 0.3178 - val_accuracy: 0.8125 - val_loss: 0.4368\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.src.callbacks.history.History at 0x249baf47fe0>"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cnn.compile(optimizer='adam', loss='binary_crossentropy', metrics=['accuracy'])\n",
    "cnn.fit(x=train_set, validation_data=test_set, epochs=25)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "s4zKCHfdHXjd"
   },
   "source": [
    "Example prediction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "id": "BITNY_tBHazP"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 36ms/step\n",
      "Dog\n",
      "\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 31ms/step\n",
      "Dog\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "from tensorflow.keras.preprocessing import image\n",
    "\n",
    "test_img_1 = image.load_img('dataset/single_prediction/cat_or_dog_1.jpg', target_size=(64, 64))\n",
    "test_img_1 = image.img_to_array(test_img_1)\n",
    "test_img_1 = np.expand_dims(test_img_1, axis=0)\n",
    "result1 = cnn.predict(test_img_1)\n",
    "if result1[0][0] == 1:\n",
    "    print('Dog\\n')\n",
    "else:\n",
    "    print('Cat\\n')\n",
    "\n",
    "test_img_2 = image.load_img('dataset/single_prediction/cat_or_dog_2.jpg', target_size=(64, 64))\n",
    "test_img_2 = image.img_to_array(test_img_2)\n",
    "test_img_2 = np.expand_dims(test_img_2, axis=0)\n",
    "result2 = cnn.predict(test_img_2)\n",
    "if result2[0][0] == 1:\n",
    "    print('Dog')\n",
    "else:\n",
    "    print('Cat')"
   ]
  }
 ],
 "metadata": {
  "colab": {
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
